_BASE_: [
  '../../ppyoloe/ppyoloe_plus_crn_s_80e_coco.yml',
]
log_iter: 20
snapshot_epoch: 2
weights: output/dt_semi_010_ppyoloe_plus_crn_s_80e_coco/model_final
# when export model for deploy, just keep _BASE_ and `dataset config`
# Then comment all the other config component (global,model,data_aug,other)


### global config
semi_supervised: True
semi_start_steps: 5000
use_ema: True
ema_decay: 0.9996
ema_decay_type: None
ema_start_steps: 3000

save_interval: &save_interval 5000
eval_interval: &eval_interval 2000

### model config
architecture: DenseTeacher
pretrain_weights: https://bj.bcebos.com/v1/paddledet/models/pretrained/ppyoloe_crn_s_obj365_pretrained.pdparams
#pretrain_weights: https://paddledet.bj.bcebos.com/models/fcos_r50_fpn_1x_coco.pdparams
DenseTeacher:
  teacher: YOLOv3
  student: YOLOv3
  train_cfg:
    ratio: 0.01
    sup_weight: 1.0
    unsup_weight: 1.0
    suppress: 'linear'
    loss_weight: {distill_loss_cls: 4.0, distill_loss_iou: 1.0, distill_loss_dfl: 1.0}
    gamma: 2.0
  test_cfg:
    inference_on: teacher
  strongAug:
    - RandomGaussianBlur: {}


### dataset config
metric: COCO
num_classes: 80
TrainDataset:
  !SemiCOCODataSet
    image_dir: train2017
    anno_path: annotations/semi_supervised/instances_train2017.1@1.json
    #image_dir: val2017
    #anno_path: annotations/instances_val2017_8img.json
    dataset_dir: /paddle/dataset/coco
    data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

UnsupTrainDataset:
  !SemiCOCODataSet
    image_dir: train2017
    anno_path: annotations/semi_supervised/instances_train2017.1@1-unlabeled.json
    #image_dir: val2017
    #anno_path: annotations/instances_val2017_8img.json
    dataset_dir: /paddle/dataset/coco
    data_fields: ['image']
    supervised: False

EvalDataset:
  !COCODataSet
    image_dir: val2017
    anno_path: annotations/instances_val2017_8img.json
    dataset_dir: /paddle/dataset/coco

TestDataset:
  !ImageFolder
    anno_path: annotations/instances_val2017.json # also support txt (like VOC's label_list.txt)
    dataset_dir: /paddle/dataset/coco # if set, anno_path will be 'dataset_dir/anno_path'


### data_aug config
worker_num: 4 # set 0 for single gpu debug
SupTrainReader:
  sample_transforms:
    - Decode: {}
    - RandomDistort: {}
    - RandomExpand: {fill_value: [123.675, 116.28, 103.53]}
    - RandomCrop: {}
    - RandomFlip: {}
  batch_transforms:
    - BatchRandomResize: {target_size: [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768], random_size: True, random_interp: True, keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
    - PadGT: {}
  batch_size: 8
  shuffle: true
  drop_last: true
  use_shared_memory: true
  collate_batch: true


UnsupTrainReader:
  sample_transforms:
    - Decode: {}
    - RandomDistort: {}
    - RandomExpand: {fill_value: [123.675, 116.28, 103.53]}
    - RandomCrop: {}
    - RandomFlip: {}
  batch_transforms:
    - BatchRandomResize: {target_size: [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768], random_size: True, random_interp: True, keep_ratio: False}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
    # - PadGT: {}
  batch_size: 8
  shuffle: true
  drop_last: true
  use_shared_memory: true
  collate_batch: true


### other config
epoch: 80
LearningRate:
  base_lr: 0.001
  schedulers:
    - !CosineDecay
      max_epochs: 96
    - !LinearWarmup
      start_factor: 0.
      epochs: 5

OptimizerBuilder:
  optimizer:
    momentum: 0.9
    type: Momentum
  regularizer:
    factor: 0.0005
    type: L2
