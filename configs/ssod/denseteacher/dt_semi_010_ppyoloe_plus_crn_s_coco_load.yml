# train from a trained supervised model weights
_BASE_: [
  '../../ppyoloe/ppyoloe_plus_crn_s_80e_coco.yml',
]
log_iter: 20
snapshot_epoch: 1
weights: output/dt_semi_010_ppyoloe_plus_crn_s_coco_load/model_final
# when export model for deploy, just keep _BASE_ and `dataset config`
# Then comment all the other config component (global,model,data_aug,other)


### global config
semi_supervised: True
semi_start_steps: 0 #3000 #5000
use_ema: True
use_meanteacher: True
ema_decay: 0.9996
ema_decay_type: None
ema_start_steps: 0 #1000 #3000

save_interval: &save_interval 5000
eval_interval: &eval_interval 2000

SSOD: DenseTeacher
DenseTeacher:
  train_cfg:
    ratio: 0.01 #
    sup_weight: 1.0
    unsup_weight: 1.0
    suppress: linear
    loss_weight: {distill_loss_cls: 2.0, distill_loss_box: 1.0} # or 2:1
    gamma: 2.0
  test_cfg: 
    #inference_on: teacher
    inference_on: student
  weakAug:
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], is_scale: true, norm_type: none}
  strongAug:
    - AugmentationUTStrong: {} # note: RandomGrayscale no use
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], is_scale: true, norm_type: none}
  sup_batch_transforms:
    - BatchRandomResize: {target_size: [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768], random_size: True, random_interp: True, keep_ratio: False}
    - Permute: {}
    - PadGT: {}
  unsup_batch_transforms:
    - BatchRandomResize: {target_size: [320, 352, 384, 416, 448, 480, 512, 544, 576, 608, 640, 672, 704, 736, 768], random_size: True, random_interp: True, keep_ratio: False}
    - Permute: {}


### dataset config
metric: COCO
num_classes: 80
TrainDataset:
  !SemiCOCODataSet
    image_dir: train2017
    anno_path: semi_annotations/instances_train2017.1@10.json
    dataset_dir: /paddle/dataset/coco
    data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

UnsupTrainDataset:
  !SemiCOCODataSet
    image_dir: train2017
    anno_path: semi_annotations/instances_train2017.1@10-unlabeled.json
    dataset_dir: /paddle/dataset/coco
    data_fields: ['image']
    supervised: False

EvalDataset:
  !COCODataSet
    image_dir: val2017
    anno_path: annotations/instances_val2017.json
    dataset_dir: /paddle/dataset/coco

TestDataset:
  !ImageFolder
    anno_path: annotations/instances_val2017.json # also support txt (like VOC's label_list.txt)
    dataset_dir: /paddle/dataset/coco # if set, anno_path will be 'dataset_dir/anno_path'


### data_aug config
worker_num: 2 # set 0 for single gpu debug
SupTrainReader:
  sample_transforms:
    - Decode: {}
    - RandomDistort: {}
    - RandomExpand: {fill_value: [123.675, 116.28, 103.53]}
    #- RandomCrop: {}
    - RandomFlip: {}
    # - RandomResize: 
    #     target_size: [[640, 640]] # only single scale
    #     #target_size: [[416, 416], [512, 512], [640, 640], [768, 768]]
    #     keep_ratio: False
    #     random_size: True
    #     random_interp: True
  batch_size: 8
  shuffle: True
  drop_last: True

UnsupTrainReader:
  sample_transforms:
    - Decode: {}
    - RandomDistort: {}
    - RandomExpand: {fill_value: [123.675, 116.28, 103.53]}
    #- RandomCrop: {} # need gt_box
    - RandomFlip: {}
    # - RandomResize:
    #     target_size: [[640, 640]] # only single scale
    #     #target_size: [[416, 416], [512, 512], [640, 640], [768, 768]]
    #     keep_ratio: False
    #     random_size: True
    #     random_interp: True
  batch_size: 8
  shuffle: True
  drop_last: True


EvalReader:
  sample_transforms:
    - Decode: {}
    - Resize: {target_size: [640, 640], keep_ratio: False, interp: 2}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
  batch_size: 2

TestReader:
  inputs_def:
    image_shape: [3, 640, 640]
  sample_transforms:
    - Decode: {}
    - Resize: {target_size: [640, 640], keep_ratio: False, interp: 2}
    - NormalizeImage: {mean: [0., 0., 0.], std: [1., 1., 1.], norm_type: none}
    - Permute: {}
  batch_size: 1


### other config
epoch: 80
LearningRate:
  base_lr: 0.001
  schedulers:
    - !CosineDecay
      max_epochs: 96
      use_warmup: False #
    - !LinearWarmup
      start_factor: 0.
      epochs: 1

OptimizerBuilder:
  optimizer:
    momentum: 0.9
    type: Momentum
  regularizer:
    factor: 0.0005 # dt-fcos 0.0001
    type: L2
  clip_grad_by_norm: 1.0 # dt-fcos


### model config
#pretrain_weights: https://bj.bcebos.com/v1/paddledet/models/pretrained/ppyoloe_crn_s_obj365_pretrained.pdparams
pretrain_weights: /paddle/ppyoloe_plus_crn_s_coco_sup010_353.pdparams
architecture: YOLOv3
norm_type: bn # sync_bn bug in ssod !!!
# use_ema: true
# ema_decay: 0.9998
# ema_black_list: ['proj_conv.weight']
# custom_black_list: ['reduce_mean']

YOLOv3:
  backbone: CSPResNet
  neck: CustomCSPPAN
  yolo_head: PPYOLOEHead
  post_process: ~


eval_size: ~ # means None, but not str 'None'
PPYOLOEHead:
  fpn_strides: [32, 16, 8]
  grid_cell_scale: 5.0
  grid_cell_offset: 0.5
  static_assigner_epoch: -1 # 30
  use_varifocal_loss: True
  loss_weight: {class: 1.0, iou: 2.5, dfl: 0.5}
  static_assigner:
    name: ATSSAssigner
    topk: 9
  assigner:
    name: TaskAlignedAssigner
    topk: 13
    alpha: 1.0
    beta: 6.0
  nms:
    name: MultiClassNMS
    nms_top_k: 1000
    keep_top_k: 300
    score_threshold: 0.01
    nms_threshold: 0.7
