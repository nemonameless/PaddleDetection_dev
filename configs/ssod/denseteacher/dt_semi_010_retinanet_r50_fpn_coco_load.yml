_BASE_: [
  '../../retinanet/retinanet_r50_fpn_1x_coco.yml',
]
log_iter: 20
snapshot_epoch: 1
weights: output/dt_semi_010_retinanet_r50_fpn_1x_coco/model_final
# when export model for deploy, just keep _BASE_ and `dataset config`
# Then comment all the other config component (global,model,data_aug,other)


### global config
semi_supervised: True
semi_start_steps: 0 #3000 #5000
use_ema: True
use_meanteacher: True
ema_decay: 0.9996
ema_decay_type: None
ema_start_steps: 0 #1000 #3000

save_interval: &save_interval 5000
eval_interval: &eval_interval 2000

SSOD: DenseTeacher
DenseTeacher:
  train_cfg:
    ratio: 0.01
    sup_weight: 1.0
    unsup_weight: 1.0
    suppress: linear
    loss_weight: {distill_loss_cls: 4.0, distill_loss_reg: 1.0}
    gamma: 2.0
  test_cfg: 
    #inference_on: teacher
    inference_on: student
  weakAug:
    - NormalizeImage: {mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225], is_scale: true}
  strongAug:
    - AugmentationUTStrong: {}
    - NormalizeImage: {mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225], is_scale: true}
  sup_batch_transforms:
    - Permute: {}
    - PadBatch: {pad_to_stride: 32}
    - PadGT: {} # do not support collate_batch: False
  unsup_batch_transforms:
    - Permute: {}
    - PadBatch: {pad_to_stride: 32}


### dataset config
metric: COCO
num_classes: 80
TrainDataset:
  !SemiCOCODataSet
    image_dir: train2017
    anno_path: semi_annotations/instances_train2017.1@10.json
    dataset_dir: /paddle/dataset/coco
    data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

UnsupTrainDataset:
  !SemiCOCODataSet
    image_dir: train2017
    anno_path: semi_annotations/instances_train2017.1@10-unlabeled.json
    dataset_dir: /paddle/dataset/coco
    data_fields: ['image']
    supervised: False

EvalDataset:
  !COCODataSet
    image_dir: val2017
    anno_path: annotations/instances_val2017.json
    dataset_dir: /paddle/dataset/coco

TestDataset:
  !ImageFolder
    anno_path: annotations/instances_val2017.json # also support txt (like VOC's label_list.txt)
    dataset_dir: /paddle/dataset/coco # if set, anno_path will be 'dataset_dir/anno_path'


### data_aug config
worker_num: 2 # set 0 for single gpu debug
SupTrainReader:
  sample_transforms:
    - Decode: {}
    - RandomResize: {target_size: [[640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], keep_ratio: True, interp: 1}
    - RandomFlip: {}
  batch_size: 2
  shuffle: True
  drop_last: True


UnsupTrainReader:
  sample_transforms:
    - Decode: {}
    - RandomResize: {target_size: [[640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], keep_ratio: True, interp: 1}
    - RandomFlip: {}
  batch_size: 2
  shuffle: True
  drop_last: True


EvalReader:
  sample_transforms:
    - Decode: {}
    - Resize: {target_size: [800, 1333], keep_ratio: True, interp: 1}
    - NormalizeImage: {is_scale: True, mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225]}
    - Permute: {}
  batch_transforms:
    - PadBatch: {pad_to_stride: 32}
  batch_size: 1


### other config
epoch: 240
LearningRate:
  base_lr: 0.01
  schedulers:
  - !PiecewiseDecay
    gamma: 0.1
    milestones: [240]
    use_warmup: False #True
  - !LinearWarmup
    start_factor: 0.1 #0.001
    steps: 10 #500

OptimizerBuilder:
  optimizer:
    momentum: 0.9
    type: Momentum
  regularizer:
    factor: 0.0001
    type: L2
  clip_grad_by_norm: 1.0



### model config
architecture: RetinaNet
#pretrain_weights: https://paddledet.bj.bcebos.com/models/pretrained/ResNet50_cos_pretrained.pdparams
pretrain_weights: /paddle/retinanet_r50_fpn_2x_coco_010_23.9.pdparams

RetinaNet:
  backbone: ResNet
  neck: FPN
  head: RetinaHead
